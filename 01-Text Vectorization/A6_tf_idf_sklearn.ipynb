{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6331fc35",
   "metadata": {},
   "source": [
    "TF-IDF en sklearn\n",
    "Vamos a calcular la TF-IDF para un corpus de texto.\n",
    "\n",
    "Puedes calcularla mediante la librería sklearn. La clase TfidfVectorizer() se encuentra en el módulo sklearn.feature_extraction.text. Impórtala como se muestra a continuación:\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Crea un contador y define palabras vacías, tal como lo hicimos con CountVectorizer():\n",
    "\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "Llama a la función fit_transform() para calcular la TF-IDF para el corpus de texto:\n",
    "\n",
    "tf_idf = count_tf_idf.fit_transform(corpus)\n",
    "\n",
    "Podemos calcular los n-gramas al pasar el argumento ngram_range a TfidfVectorizer().\n",
    "\n",
    "Si los datos se dividen en conjuntos de entrenamiento y prueba, llama a la función fit() solo para el conjunto de entrenamiento. De lo contrario, la prueba estará sesgada, porque el modelo tomará en cuenta las frecuencias de las palabras del conjunto de prueba.\n",
    "\n",
    "Crea una matriz con valores TF-IDF para el corpus de reseñas. Guárdala en la variable tf_idf. Imprime el tamaño de la matriz (en precódigo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d85f22",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "- Crea una matriz con valores TF-IDF para el corpus de reseñas. \n",
    "- Guárdala en la variable tf_idf. \n",
    "- Imprime el tamaño de la matriz (en precódigo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "data = pd.read_csv('/datasets/imdb_reviews_small_lemm.tsv', sep='\\t')\n",
    "corpus = data['review_lemm']\n",
    "\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "tf_idf=count_tf_idf.fit_transform(corpus)  #  < escribe tu código aquí >\n",
    "\n",
    "print('El tamaño de la matriz TF-IDF:', tf_idf.shape)\n",
    "\n",
    "#output\n",
    "#El tamaño de la matriz TF-IDF: (4541, 26098)\n",
    "\n",
    "\"\"\"¡Es correcto!\n",
    "\n",
    "Tenemos una matriz con valores TF-IDF. \n",
    "El número de características es el mismo que obtuvimos para \n",
    "la bolsa de palabras. No hay ningún error aquí: \n",
    "¡las palabras son las mismas!\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983d472f",
   "metadata": {},
   "source": [
    "Qu hace el codigo:\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Importas pandas para manejar datos, stopwords de NLTK (lista de palabras vacías) y TfidfVectorizer de scikit-learn para convertir texto a TF-IDF.\n",
    "\n",
    "\n",
    "data = pd.read_csv('/datasets/imdb_reviews_small_lemm.tsv', sep='\\t')\n",
    "corpus = data['review_lemm']\n",
    "\n",
    "Cargas el archivo TSV (separado por tabuladores).\n",
    "\n",
    "Tomas la columna review_lemm (reseñas ya limpias y lematizadas) como tu corpus (lista/serie de textos).\n",
    "\n",
    "\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "Creas un conjunto de stopwords en inglés (palabras muy comunes que no aportan significado).\n",
    "\n",
    "\n",
    "Configuras el vectorizador TF-IDF para ignorar esas palabras al construir el vocabulario.\n",
    "\n",
    "tf_idf = count_tf_idf.fit_transform(corpus)\n",
    "\n",
    "\n",
    "fit: aprende el vocabulario (todas las palabras “útiles”) y calcula el vector IDF (qué tan raras/comunes son en el corpus).\n",
    "\n",
    "transform: convierte cada documento en un vector numérico de pesos TF-IDF.\n",
    "\n",
    "\n",
    "Resultado: una matriz dispersa (sparse) donde:\n",
    "\n",
    "Filas = documentos (reseñas).\n",
    "\n",
    "Columnas = términos (palabras del vocabulario).\n",
    "\n",
    "Valores = peso TF-IDF de cada palabra en cada documento.\n",
    "\n",
    "print('El tamaño de la matriz TF-IDF:', tf_idf.shape)\n",
    "\n",
    "\n",
    "Muestra la forma de la matriz.\n",
    "\n",
    "Tu salida: (4541, 26098) significa:\n",
    "\n",
    "4541 reseñas en el corpus.\n",
    "\n",
    "26,098 palabras únicas en el vocabulario después de quitar stopwords y aplicar las reglas de tokenización de scikit-learn.\n",
    "\n",
    "Cómo interpretar la matriz TF-IDF\n",
    "\n",
    "Valores altos en una celda ⇒ esa palabra es frecuente en esa reseña y relativamente rara en el resto del corpus (por eso es informativa).\n",
    "\n",
    "Valores bajos o 0 ⇒ palabra poco relevante para esa reseña, o ni siquiera aparece.\n",
    "\n",
    "La matriz es dispersa porque la mayoría de palabras no aparecen en la mayoría de reseñas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62aa48f8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_text_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
