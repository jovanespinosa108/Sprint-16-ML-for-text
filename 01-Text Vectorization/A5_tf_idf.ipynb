{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e714a10b",
   "metadata": {},
   "source": [
    "🔹 ¿Qué es TF-IDF?\n",
    "\n",
    "TF (Term Frequency) → mide qué tan frecuente es una palabra dentro de un documento.\n",
    "\n",
    "IDF (Inverse Document Frequency) → mide qué tan rara es una palabra en el corpus (conjunto de documentos).\n",
    "\n",
    "TF-IDF = TF × IDF → da un peso mayor a palabras que son importantes en un documento, pero no comunes en todos los documentos.\n",
    "\n",
    "🔹 Ejemplo 1: Contando palabras (TF simple)\n",
    "\n",
    "Imagina dos reseñas:\n",
    "\n",
    "Doc1: \"the movie was great great great\"\n",
    "\n",
    "Doc2: \"the movie was bad\"\n",
    "\n",
    "👉 La palabra \"great\" aparece 3 veces en Doc1, así que tiene más peso en ese documento.\n",
    "\n",
    "🔹 Ejemplo 2: Importancia en el corpus (IDF)\n",
    "\n",
    "Si en todas las reseñas aparece \"the\", entonces su IDF será muy bajo → no aporta información.\n",
    "Pero si \"great\" solo aparece en pocas reseñas, su IDF será alto → aporta información valiosa.\n",
    "\n",
    "🔹 Ejemplo 3: Combinación TF-IDF\n",
    "\n",
    "En Doc1, \"great\" tendrá un peso alto (muchas veces y poco común).\n",
    "\n",
    "En Doc2, \"bad\" también tendrá un peso alto (aunque solo aparece una vez, es rara y por eso destaca).\n",
    "\n",
    "\"the\", \"was\", \"movie\" → tendrán peso casi cero (muy comunes).\n",
    "\n",
    "🔹 ¿Cómo se usa en Machine Learning?\n",
    "\n",
    "Transformar texto en números:\n",
    "\n",
    "El texto se convierte en una matriz (documentos × palabras) con valores TF-IDF.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "Doc1: [0.0, 0.8, 0.0, 0.6]  # pesos de palabras\n",
    "Doc2: [0.5, 0.0, 0.7, 0.0]\n",
    "\n",
    "\n",
    "Entrenar un modelo ML:\n",
    "\n",
    "Clasificación de reseñas (positiva/negativa).\n",
    "\n",
    "Detección de spam.\n",
    "\n",
    "Agrupamiento de documentos.\n",
    "\n",
    "Interpretación de resultados:\n",
    "\n",
    "Palabras con alto peso TF-IDF son las que más ayudan al modelo a diferenciar entre clases.\n",
    "\n",
    "Ejemplo: en reseñas de películas, \"great\", \"amazing\", \"boring\", \"awful\" tendrán alto peso → el modelo las usa para aprender sentimientos.\n",
    "\n",
    "👉 En pocas palabras:\n",
    "\n",
    "BoW = cuenta palabras sin importancia relativa.\n",
    "\n",
    "TF-IDF = da importancia a palabras diferenciadoras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca01f1",
   "metadata": {},
   "source": [
    "🔹 1. Fórmulas básicas\n",
    "\n",
    "TF (Term Frequency) = frecuencia de la palabra en el documento\n",
    "\n",
    "𝑇𝐹=𝑡𝑛\n",
    "\n",
    "donde\n",
    "\n",
    "𝑡 = número de veces que aparece la palabra en el documento\n",
    "\n",
    "𝑛 = número total de palabras en el documento\n",
    "\n",
    "IDF (Inverse Document Frequency) = mide cuán rara es la palabra en todo el corpus\n",
    "\n",
    "𝐼𝐷𝐹=log10(𝐷𝑑)\n",
    "\n",
    "donde\n",
    "\n",
    "𝐷 = número total de documentos\n",
    "\n",
    "𝑑 = número de documentos que contienen esa palabra\n",
    "\n",
    "TF-IDF = combinación de ambos\n",
    "\n",
    "𝑇𝐹-𝐼𝐷𝐹=𝑇𝐹×𝐼𝐷𝐹\n",
    "\n",
    "🔹 2. Ejemplo explicado (con \"río\")\n",
    "\n",
    "Corpus: 20 poemas → 𝐷=20\n",
    "\n",
    "\n",
    "Primer poema: 40 palabras → 𝑛=40\n",
    "\n",
    "\"río\" aparece 5 veces → 𝑡=5\n",
    "\n",
    "\"río\" está en 2 poemas → =2\n",
    "\n",
    "\n",
    "a) Calcular TF\n",
    "𝑇𝐹=𝑡/𝑛=5/40=0.125\n",
    "TF=nt\t​=40/5\t=0.125\n",
    "\n",
    "👉 En el primer poema, la palabra “río” representa 12.5% del texto.\n",
    "\n",
    "b) Calcular IDF\n",
    "𝐼𝐷𝐹=log10(𝐷/𝑑)=log10(20/2)=log10(10)=1\n",
    "\n",
    "\n",
    "👉 Como “río” aparece solo en 2 de los 20 poemas, es poco común → IDF = 1.\n",
    "\n",
    "c) Calcular TF-IDF\n",
    "𝑇𝐹-𝐼𝐷𝐹=𝑇F x IDF = 0.125 x 1 = 0.125\n",
    "\n",
    "\n",
    "👉 El peso de la palabra “río” en este poema es 0.125.\n",
    "\n",
    "🔹 3. Interpretación\n",
    "\n",
    "TF alto → la palabra aparece mucho en un documento.\n",
    "\n",
    "IDF alto → la palabra aparece en pocos documentos (es rara).\n",
    "\n",
    "TF-IDF alto → palabra muy representativa de un documento en particular.\n",
    "\n",
    "En este ejemplo:\n",
    "\n",
    "“río” es importante en el primer poema porque aparece varias veces.\n",
    "\n",
    "También es relevante en el corpus porque no aparece en la mayoría de los demás poemas.\n",
    "\n",
    "Resultado: TF-IDF medio-alto (0.125).\n",
    "\n",
    "💡 Piensa así:\n",
    "\n",
    "Palabras como “the”, “and”, “de” → TF alto, pero IDF bajo (salen en todos lados).\n",
    "\n",
    "Palabras como “río”, “dragón”, “galaxia” → TF medio/alto + IDF alto → son las que diferencian documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b75b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      el     en     es  grande  gusta  largo    mar     me  nadar  profundo  \\\n",
      "0  0.315  0.000  0.406   0.000  0.000  0.534  0.000  0.000  0.000     0.000   \n",
      "1  0.266  0.451  0.000   0.000  0.451  0.000  0.000  0.451  0.451     0.000   \n",
      "2  0.298  0.000  0.384   0.505  0.000  0.000  0.505  0.000  0.000     0.505   \n",
      "\n",
      "     río  tranquilo  \n",
      "0  0.406      0.534  \n",
      "1  0.343      0.000  \n",
      "2  0.000      0.000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Nuestro mini corpus (3 documentos)\n",
    "corpus = [\n",
    "    \"el río es largo y tranquilo\",\n",
    "    \"me gusta nadar en el río\",\n",
    "    \"el mar es grande y profundo\"\n",
    "]\n",
    "\n",
    "# Creamos el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustamos y transformamos el corpus\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convertimos a DataFrame para verlo más claro\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(df.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316db945",
   "metadata": {},
   "source": [
    "🔹 Cómo leer la tabla\n",
    "\n",
    "Cada fila = un documento del corpus.\n",
    "\n",
    "Cada columna = una palabra del vocabulario.\n",
    "\n",
    "Cada valor = peso TF-IDF de esa palabra en ese documento.\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "En Doc1 (\"el río es largo y tranquilo\") → \"río\" tiene peso 0.556 → es representativa de este documento.\n",
    "\n",
    "En Doc2 (\"me gusta nadar en el río\") → \"me\", \"gusta\", \"nadar\" tienen peso alto, \"río\" también destaca.\n",
    "\n",
    "En Doc3 (\"el mar es grande y profundo\") → \"mar\", \"grande\", \"profundo\" tienen los mayores valores → palabras únicas que diferencian este documento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_text_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
