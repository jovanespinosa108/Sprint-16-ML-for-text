{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e714a10b",
   "metadata": {},
   "source": [
    "ğŸ”¹ Â¿QuÃ© es TF-IDF?\n",
    "\n",
    "TF (Term Frequency) â†’ mide quÃ© tan frecuente es una palabra dentro de un documento.\n",
    "\n",
    "IDF (Inverse Document Frequency) â†’ mide quÃ© tan rara es una palabra en el corpus (conjunto de documentos).\n",
    "\n",
    "TF-IDF = TF Ã— IDF â†’ da un peso mayor a palabras que son importantes en un documento, pero no comunes en todos los documentos.\n",
    "\n",
    "ğŸ”¹ Ejemplo 1: Contando palabras (TF simple)\n",
    "\n",
    "Imagina dos reseÃ±as:\n",
    "\n",
    "Doc1: \"the movie was great great great\"\n",
    "\n",
    "Doc2: \"the movie was bad\"\n",
    "\n",
    "ğŸ‘‰ La palabra \"great\" aparece 3 veces en Doc1, asÃ­ que tiene mÃ¡s peso en ese documento.\n",
    "\n",
    "ğŸ”¹ Ejemplo 2: Importancia en el corpus (IDF)\n",
    "\n",
    "Si en todas las reseÃ±as aparece \"the\", entonces su IDF serÃ¡ muy bajo â†’ no aporta informaciÃ³n.\n",
    "Pero si \"great\" solo aparece en pocas reseÃ±as, su IDF serÃ¡ alto â†’ aporta informaciÃ³n valiosa.\n",
    "\n",
    "ğŸ”¹ Ejemplo 3: CombinaciÃ³n TF-IDF\n",
    "\n",
    "En Doc1, \"great\" tendrÃ¡ un peso alto (muchas veces y poco comÃºn).\n",
    "\n",
    "En Doc2, \"bad\" tambiÃ©n tendrÃ¡ un peso alto (aunque solo aparece una vez, es rara y por eso destaca).\n",
    "\n",
    "\"the\", \"was\", \"movie\" â†’ tendrÃ¡n peso casi cero (muy comunes).\n",
    "\n",
    "ğŸ”¹ Â¿CÃ³mo se usa en Machine Learning?\n",
    "\n",
    "Transformar texto en nÃºmeros:\n",
    "\n",
    "El texto se convierte en una matriz (documentos Ã— palabras) con valores TF-IDF.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "Doc1: [0.0, 0.8, 0.0, 0.6]  # pesos de palabras\n",
    "Doc2: [0.5, 0.0, 0.7, 0.0]\n",
    "\n",
    "\n",
    "Entrenar un modelo ML:\n",
    "\n",
    "ClasificaciÃ³n de reseÃ±as (positiva/negativa).\n",
    "\n",
    "DetecciÃ³n de spam.\n",
    "\n",
    "Agrupamiento de documentos.\n",
    "\n",
    "InterpretaciÃ³n de resultados:\n",
    "\n",
    "Palabras con alto peso TF-IDF son las que mÃ¡s ayudan al modelo a diferenciar entre clases.\n",
    "\n",
    "Ejemplo: en reseÃ±as de pelÃ­culas, \"great\", \"amazing\", \"boring\", \"awful\" tendrÃ¡n alto peso â†’ el modelo las usa para aprender sentimientos.\n",
    "\n",
    "ğŸ‘‰ En pocas palabras:\n",
    "\n",
    "BoW = cuenta palabras sin importancia relativa.\n",
    "\n",
    "TF-IDF = da importancia a palabras diferenciadoras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca01f1",
   "metadata": {},
   "source": [
    "ğŸ”¹ 1. FÃ³rmulas bÃ¡sicas\n",
    "\n",
    "TF (Term Frequency) = frecuencia de la palabra en el documento\n",
    "\n",
    "ğ‘‡ğ¹=ğ‘¡ğ‘›\n",
    "\n",
    "donde\n",
    "\n",
    "ğ‘¡ = nÃºmero de veces que aparece la palabra en el documento\n",
    "\n",
    "ğ‘› = nÃºmero total de palabras en el documento\n",
    "\n",
    "IDF (Inverse Document Frequency) = mide cuÃ¡n rara es la palabra en todo el corpus\n",
    "\n",
    "ğ¼ğ·ğ¹=log10(ğ·ğ‘‘)\n",
    "\n",
    "donde\n",
    "\n",
    "ğ· = nÃºmero total de documentos\n",
    "\n",
    "ğ‘‘ = nÃºmero de documentos que contienen esa palabra\n",
    "\n",
    "TF-IDF = combinaciÃ³n de ambos\n",
    "\n",
    "ğ‘‡ğ¹-ğ¼ğ·ğ¹=ğ‘‡ğ¹Ã—ğ¼ğ·ğ¹\n",
    "\n",
    "ğŸ”¹ 2. Ejemplo explicado (con \"rÃ­o\")\n",
    "\n",
    "Corpus: 20 poemas â†’ ğ·=20\n",
    "\n",
    "\n",
    "Primer poema: 40 palabras â†’ ğ‘›=40\n",
    "\n",
    "\"rÃ­o\" aparece 5 veces â†’ ğ‘¡=5\n",
    "\n",
    "\"rÃ­o\" estÃ¡ en 2 poemas â†’ =2\n",
    "\n",
    "\n",
    "a) Calcular TF\n",
    "ğ‘‡ğ¹=ğ‘¡/ğ‘›=5/40=0.125\n",
    "TF=nt\tâ€‹=40/5\t=0.125\n",
    "\n",
    "ğŸ‘‰ En el primer poema, la palabra â€œrÃ­oâ€ representa 12.5% del texto.\n",
    "\n",
    "b) Calcular IDF\n",
    "ğ¼ğ·ğ¹=log10(ğ·/ğ‘‘)=log10(20/2)=log10(10)=1\n",
    "\n",
    "\n",
    "ğŸ‘‰ Como â€œrÃ­oâ€ aparece solo en 2 de los 20 poemas, es poco comÃºn â†’ IDF = 1.\n",
    "\n",
    "c) Calcular TF-IDF\n",
    "ğ‘‡ğ¹-ğ¼ğ·ğ¹=ğ‘‡F x IDF = 0.125 x 1 = 0.125\n",
    "\n",
    "\n",
    "ğŸ‘‰ El peso de la palabra â€œrÃ­oâ€ en este poema es 0.125.\n",
    "\n",
    "ğŸ”¹ 3. InterpretaciÃ³n\n",
    "\n",
    "TF alto â†’ la palabra aparece mucho en un documento.\n",
    "\n",
    "IDF alto â†’ la palabra aparece en pocos documentos (es rara).\n",
    "\n",
    "TF-IDF alto â†’ palabra muy representativa de un documento en particular.\n",
    "\n",
    "En este ejemplo:\n",
    "\n",
    "â€œrÃ­oâ€ es importante en el primer poema porque aparece varias veces.\n",
    "\n",
    "TambiÃ©n es relevante en el corpus porque no aparece en la mayorÃ­a de los demÃ¡s poemas.\n",
    "\n",
    "Resultado: TF-IDF medio-alto (0.125).\n",
    "\n",
    "ğŸ’¡ Piensa asÃ­:\n",
    "\n",
    "Palabras como â€œtheâ€, â€œandâ€, â€œdeâ€ â†’ TF alto, pero IDF bajo (salen en todos lados).\n",
    "\n",
    "Palabras como â€œrÃ­oâ€, â€œdragÃ³nâ€, â€œgalaxiaâ€ â†’ TF medio/alto + IDF alto â†’ son las que diferencian documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b75b813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      el     en     es  grande  gusta  largo    mar     me  nadar  profundo  \\\n",
      "0  0.315  0.000  0.406   0.000  0.000  0.534  0.000  0.000  0.000     0.000   \n",
      "1  0.266  0.451  0.000   0.000  0.451  0.000  0.000  0.451  0.451     0.000   \n",
      "2  0.298  0.000  0.384   0.505  0.000  0.000  0.505  0.000  0.000     0.505   \n",
      "\n",
      "     rÃ­o  tranquilo  \n",
      "0  0.406      0.534  \n",
      "1  0.343      0.000  \n",
      "2  0.000      0.000  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "# Nuestro mini corpus (3 documentos)\n",
    "corpus = [\n",
    "    \"el rÃ­o es largo y tranquilo\",\n",
    "    \"me gusta nadar en el rÃ­o\",\n",
    "    \"el mar es grande y profundo\"\n",
    "]\n",
    "\n",
    "# Creamos el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustamos y transformamos el corpus\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Convertimos a DataFrame para verlo mÃ¡s claro\n",
    "df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(df.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316db945",
   "metadata": {},
   "source": [
    "ğŸ”¹ CÃ³mo leer la tabla\n",
    "\n",
    "Cada fila = un documento del corpus.\n",
    "\n",
    "Cada columna = una palabra del vocabulario.\n",
    "\n",
    "Cada valor = peso TF-IDF de esa palabra en ese documento.\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "En Doc1 (\"el rÃ­o es largo y tranquilo\") â†’ \"rÃ­o\" tiene peso 0.556 â†’ es representativa de este documento.\n",
    "\n",
    "En Doc2 (\"me gusta nadar en el rÃ­o\") â†’ \"me\", \"gusta\", \"nadar\" tienen peso alto, \"rÃ­o\" tambiÃ©n destaca.\n",
    "\n",
    "En Doc3 (\"el mar es grande y profundo\") â†’ \"mar\", \"grande\", \"profundo\" tienen los mayores valores â†’ palabras Ãºnicas que diferencian este documento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_text_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
