{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2c5de2",
   "metadata": {},
   "source": [
    "üîπ ¬øQu√© es el an√°lisis de sentimiento?\n",
    "\n",
    "Es una t√©cnica de Procesamiento de Lenguaje Natural (NLP) que busca identificar y clasificar las emociones u opiniones expresadas en un texto.\n",
    "\n",
    "En palabras simples: trata de responder si un texto expresa algo positivo, negativo o neutral.\n",
    "\n",
    "üîπ ¬øC√≥mo funciona?\n",
    "\n",
    "Recolectar datos ‚Üí Ejemplo: rese√±as de pel√≠culas, comentarios en redes sociales, encuestas.\n",
    "\n",
    "Procesar el texto ‚Üí Limpieza, lematizaci√≥n, eliminaci√≥n de stopwords.\n",
    "\n",
    "Convertir en n√∫meros ‚Üí Usando BoW, TF-IDF, o embeddings como Word2Vec o BERT.\n",
    "\n",
    "Entrenar un modelo de ML ‚Üí Clasificador (Regresi√≥n Log√≠stica, SVM, Redes Neuronales) que aprenda a distinguir entre sentimientos.\n",
    "\n",
    "Clasificaci√≥n ‚Üí El modelo predice si un nuevo texto es positivo, negativo o neutral.\n",
    "\n",
    "üîπ Ejemplos\n",
    "\n",
    "Texto: ‚ÄúLa pel√≠cula fue incre√≠ble, me encant√≥‚Äù ‚Üí Positivo üéâ\n",
    "\n",
    "Texto: ‚ÄúEl servicio fue terrible, no lo recomiendo‚Äù ‚Üí Negativo üò°\n",
    "\n",
    "Texto: ‚ÄúEl producto lleg√≥ ayer‚Äù ‚Üí Neutral üòê\n",
    "\n",
    "üîπ Nombre en ingl√©s\n",
    "\n",
    "El t√©rmino es:\n",
    "üëâ Sentiment Analysis\n",
    "\n",
    "Otros sin√≥nimos que se usan en ingl√©s:\n",
    "\n",
    "Opinion Mining\n",
    "\n",
    "Sentiment Classification\n",
    "\n",
    "üí° Se usa mucho en:\n",
    "\n",
    "Opiniones de clientes (e-commerce, rese√±as de productos).\n",
    "\n",
    "Redes sociales (monitorear percepci√≥n de una marca).\n",
    "\n",
    "Encuestas pol√≠ticas (analizar opiniones sobre candidatos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f4ac471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en test: 0.5\n",
      "Predicciones: [0 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- 1. Dataset de ejemplo (peque√±o, t√∫ puedes usar imdb_reviews_small_lemm.tsv) ---\n",
    "data = {\n",
    "    \"review\": [\n",
    "        \"I loved this movie, it was fantastic!\",\n",
    "        \"What a terrible film, waste of time.\",\n",
    "        \"Absolutely wonderful experience, highly recommend.\",\n",
    "        \"The acting was awful and the story boring.\",\n",
    "        \"Great movie, will watch it again!\",\n",
    "        \"Worst movie I have ever seen.\"\n",
    "    ],\n",
    "    \"sentiment\": [1, 0, 1, 0, 1, 0]  # 1 = positivo, 0 = negativo\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# --- 2. Dividir en entrenamiento y prueba ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"review\"], df[\"sentiment\"], test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# --- 3. Convertir texto a TF-IDF ---\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X_train_tf = vectorizer.fit_transform(X_train)\n",
    "X_test_tf = vectorizer.transform(X_test)\n",
    "\n",
    "# --- 4. Entrenar modelo de clasificaci√≥n ---\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tf, y_train)\n",
    "\n",
    "# --- 5. Evaluar en test ---\n",
    "y_pred = model.predict(X_test_tf)\n",
    "print(\"Accuracy en test:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# --- 6. Probar con frases nuevas ---\n",
    "nuevas = [\"This film was amazing!\", \"I hated this movie so much.\"]\n",
    "nuevas_tf = vectorizer.transform(nuevas)\n",
    "print(\"Predicciones:\", model.predict(nuevas_tf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113a626a",
   "metadata": {},
   "source": [
    "üîπ ¬øQu√© pasa aqu√≠?\n",
    "\n",
    "1. Dataset peque√±o ‚Üí rese√±as con etiqueta 1 (positivo) o 0 (negativo).\n",
    "\n",
    "2. TF-IDF convierte las rese√±as en vectores num√©ricos.\n",
    "\n",
    "3. Logistic Regression aprende a distinguir patrones de palabras positivas (‚Äúloved‚Äù, ‚Äúgreat‚Äù) y negativas (‚Äúawful‚Äù, ‚Äúwaste‚Äù).\n",
    "\n",
    "4. El modelo se eval√∫a con accuracy (qu√© tan bien clasifica).\n",
    "\n",
    "5. Probamos con frases nuevas ‚Üí el modelo predice el sentimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148149d7",
   "metadata": {},
   "source": [
    "Para determinar el tono del texto, vamos a usar valores TF-IDF como caracter√≠sticas.\n",
    "\n",
    "El an√°lisis de sentimiento identifica textos cargados de emociones. Esta herramienta puede ser extremadamente √∫til en los negocios al evaluar las reacciones de los consumidores ante un nuevo producto. Un humano necesitar√≠a varias horas para analizar miles de rese√±as, mientras que una computadora lo har√≠a en un par de minutos.\n",
    "\n",
    "El an√°lisis de sentimiento funciona etiquetando el texto como positivo o negativo. Al texto positivo se le asigna un \"1\" y al texto negativo se le asigna un \"0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a30a0",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "\n",
    "Tu objetivo ahora es entrenar una regresi√≥n log√≠stica para determinar la tonalidad de las rese√±as.\n",
    "\n",
    "Tanto el dataset de entrenamiento como el conjunto de datos de prueba ya se han le√≠do en el prec√≥digo. Esto es lo que te pedimos que hagas:\n",
    "\n",
    "1. Extrae rese√±as lematizadas que se utilizar√°n para prop√≥sitos de entrenamiento y gu√°rdalos en la variable train_corpus. Es importante observar que las rese√±as lematizadas est√°n en la columna review_lemm del dataset, as√≠ que no tendr√°s que lematizar rese√±as por tu cuenta.\n",
    "2. Establece las palabras vac√≠as y gu√°rdalas en la variable stop_words.\n",
    "3. Inicializa el TF_IDF vectorizer y gu√°rdalo en la variable count_tf_idf.\n",
    "4. Ajusta y transforma el corpus de entrenamiento, y guarda los resultados en la variable tf_idf.\n",
    "5. Las caracter√≠sticas que se usar√°n para el entrenamiento son los valores almacenados en la variable tf idf, as√≠ que establece features train en ella.\n",
    "6. Los objetivos se encuentran en la columna pos del conjunto de datos (0 - rese√±a negativa, 1 - rese√±a positiva). Extrae los objetivos para fines de entrenamientos utilizando el nombre de la columna y gu√°rdalos en la variable target_train.\n",
    "7. Al igual que en el primer punto, extrae las rese√±as lematizadas para probarlas y gu√°rdalas en la variable test_corpus.\n",
    "8. Obt√©n las caracter√≠sticas para probar transformando las rese√±as lematizadas utilizando TF_IDF vectorizer, que utilizaste para el entrenamiento. Almacena los resultados de la transformaci√≥n en la variable features_test.\n",
    "9. Inicializa el modelo de regresi√≥n log√≠stica en la variable model y aj√∫stalo con las caracter√≠sticas de entrenamiento y los objetivos.\n",
    "10. Obt√©n predicciones para las caracter√≠sticas de prueba y almac√©nalos en la variable pred_test.\n",
    "\n",
    "Las predicciones resultantes ser√°n verificadas y si la precisi√≥n que alcanza tu modelo excede el 82%, se aceptar√° tu soluci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_data = pd.read_csv('/datasets/imdb_reviews_small_lemm_train.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('/datasets/imdb_reviews_small_lemm_test.tsv', sep='\\t')\n",
    "\n",
    "train_corpus = train_data['review_lemm']# extraer rese√±as lematizadas para el entrenamiento\n",
    "stop_words = set(nltk_stopwords.words('english'))# definir las palabras vac√≠as\n",
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stop_words)# inicializar TfidVercorizer\n",
    "tf_idf = count_tf_idf.fit_transform(train_corpus)# ajustar y transformar el corpus de entrenamiento\n",
    "\n",
    "features_train = tf_idf# extraer caracter√≠sticas para el entrenamiento\n",
    "target_train = train_data['pos']# extraer la columna objetivo\n",
    "\n",
    "test_corpus = test_data['review_lemm']# extraer rese√±as lematizadas para la prueba\n",
    "features_test = count_tf_idf.transform(test_corpus)# transformar el corpus de entrenamiento\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(features_train, target_train)# inicializar el modelo de regresi√≥n log√≠stica y ajustarlo\n",
    "pred_test = model.predict(features_test)# obtener predicciones para la parte de prueba de los datos\n",
    "\n",
    "# transformar las predicciones en un DataFrame y guardarlo\n",
    "submission = pd.DataFrame({'pos':pred_test})\n",
    "print(submission)\n",
    "\n",
    "#output\n",
    "\"\"\"      pos\n",
    "0       0\n",
    "1       1\n",
    "2       1\n",
    "3       1\n",
    "4       0\n",
    "...   ...\n",
    "2215    0\n",
    "2216    1\n",
    "2217    1\n",
    "2218    1\n",
    "2219    1\n",
    "\n",
    "[2220 rows x 1 columns]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f44558",
   "metadata": {},
   "source": [
    "üîé ¬øC√≥mo decide el modelo?\n",
    "\n",
    "TF-IDF vectorizer convierte cada rese√±a en un vector de n√∫meros, donde cada n√∫mero indica qu√© tan importante es una palabra en esa rese√±a comparada con todas las dem√°s.\n",
    "\n",
    "Regresi√≥n log√≠stica asigna un peso (coeficiente) a cada palabra.\n",
    "\n",
    "Si el peso es positivo üëâ la palabra empuja la predicci√≥n hacia rese√±a positiva (1).\n",
    "\n",
    "Si el peso es negativo üëâ la palabra empuja la predicci√≥n hacia rese√±a negativa (0).\n",
    "\n",
    "üìä Ejemplo t√≠pico en rese√±as de cine\n",
    "\n",
    "Palabras con peso positivo (asociadas a rese√±as positivas):\n",
    "\"amazing\", \"excellent\", \"great\", \"wonderful\", \"love\".\n",
    "\n",
    "Palabras con peso negativo (asociadas a rese√±as negativas):\n",
    "\"boring\", \"awful\", \"waste\", \"terrible\", \"bad\".\n",
    "\n",
    "üõ† C√≥mo ver esto en tu c√≥digo\n",
    "\n",
    "Podemos revisar los coeficientes que aprendi√≥ el modelo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ea91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los pesos del modelo\n",
    "feature_names = count_tf_idf.get_feature_names_out()\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Palabras m√°s positivas\n",
    "top_pos = sorted(zip(coefficients, feature_names), reverse=True)[:10]\n",
    "\n",
    "# Palabras m√°s negativas\n",
    "top_neg = sorted(zip(coefficients, feature_names))[:10]\n",
    "\n",
    "print(\"üîπ Palabras m√°s asociadas a rese√±as positivas:\")\n",
    "for coef, word in top_pos:\n",
    "    print(f\"{word}: {coef:.3f}\")\n",
    "\n",
    "print(\"\\nüîπ Palabras m√°s asociadas a rese√±as negativas:\")\n",
    "for coef, word in top_neg:\n",
    "    print(f\"{word}: {coef:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2b935",
   "metadata": {},
   "source": [
    "üìå Lo que ver√°s\n",
    "\n",
    "Una lista de las 10 palabras que m√°s empujan a positivo (con coeficientes grandes y positivos).\n",
    "\n",
    "Una lista de las 10 palabras que m√°s empujan a negativo (con coeficientes negativos).\n",
    "\n",
    "Esto te muestra directamente c√≥mo el modelo \"piensa\" al clasificar sentimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01250c7",
   "metadata": {},
   "source": [
    "Conclusi√≥n\n",
    "\n",
    "En este cap√≠tulo aprendiste a:\n",
    "\n",
    "calcular vectores de texto usando el m√©todo \"bolsa de palabras\";\n",
    "crear caracter√≠sticas con TF-IDF;\n",
    "resolver tareas de clasificaci√≥n de textos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_for_text_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
