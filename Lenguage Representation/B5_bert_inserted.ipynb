{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38815231",
   "metadata": {},
   "source": [
    "Insertados de BERT\n",
    "\n",
    "Supongamos que la lista de los ID de vector (relleno) y la lista de máscaras de atención se formaron de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9137770",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_list = []\n",
    "attention_mask_list = []\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "for input_text in corpus[:200]:\n",
    "    ids = tokenizer.encode(\n",
    "        input_text.lower(),\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "    )\n",
    "    padded = np.array(ids + [0] * (max_length - len(ids)))\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "    ids_list.append(padded)\n",
    "    attention_mask_list.append(attention_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add0f610",
   "metadata": {},
   "source": [
    "Ya casi tenemos todo listo para formar vectores con el modelo BERT y clasificar las reseñas. Es hora de pasar a los tensores.\n",
    "\n",
    "Inicializa la configuración BertConfig. Pásale un archivo JSON con la descripción de la configuración del modelo. JSON (notación de objetos de JavaScript) es un flujo de números, letras, dos puntos y corchetes que devuelve un servidor cuando se le llama.\n",
    "\n",
    "Inicializa el modelo de la clase BertModel. Pasa el archivo con el modelo previamente entrenado y la configuración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773180cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbf9bb7",
   "metadata": {},
   "source": [
    "Vamos a comenzar por convertir textos en insertados. Esto puede tardar varios minutos, así que accede a la biblioteca tqdm (árabe: taqadum, تقدّم, “progreso”). Esta muestra el progreso de la operación. Luego simplemente envuelve tu bucle en tqdm(). Utiliza tqdm.auto para importar la opción correcta para tu plataforma. Mira cómo funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865345c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for i in tqdm(range(int(8e6))):\n",
    "    pass\n",
    "\n",
    "# aparecerá la barra de progreso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb8402",
   "metadata": {},
   "source": [
    "El modelo BERT crea insertados en lotes. Haz pequeño el tamaño del lote para que la RAM no se vea abrumada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d309581",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eba848",
   "metadata": {},
   "source": [
    "Haz un bucle para los lotes. La función tqdm() indicará el progreso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e622017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creación de una lista vacía de insertados de reseñas\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(len(ids_list) // batch_size)):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e4ef03",
   "metadata": {},
   "source": [
    "Transforma los datos en un formato de tensor. Tensor es un vector multidimensional en la librería Torch. El tipo de datos LongTensor almacena números en \"formato largo\", es decir, asigna 64 bits para cada número."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77396c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  unión de vectores de ids (de tokens) a un tensor\n",
    "ids_batch = torch.LongTensor(ids_list[batch_size*i:batch_size*(i+1)])\n",
    "# unión de vectores de máscaras de atención a un tensor\n",
    "attention_mask_batch = torch.LongTensor(attention_mask_list[batch_size*i:batch_size*(i+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f41a5",
   "metadata": {},
   "source": [
    "Pasa los datos y la máscara al modelo para obtener insertados para el lote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5032ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_embeddings = model(ids_batch, attention_mask=attention_mask_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbcb828",
   "metadata": {},
   "source": [
    "Utiliza la función  no_grad()(sin gradiente) para indicar que no necesitas gradientes en la librería Torch (al crear tu propio modelo BERT necesitas los gradientes para el modo de entrenamiento). Esta hará los cálculos más rápido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7409ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    batch_embeddings = model(ids_batch, attention_mask=attention_mask_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200bd83c",
   "metadata": {},
   "source": [
    "Extrae los elementos requeridos del tensor y agrega la lista de todos los insertados:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c67da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convierte elementos de tensor a numpy.array con la función numpy()\n",
    "embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8178e8",
   "metadata": {},
   "source": [
    "Uniendo todo lo anterior, obtenemos este bucle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef40235",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for i in tqdm(range(len(ids_list) // batch_size)):\n",
    "\n",
    "    ids_batch = torch.LongTensor(\n",
    "        ids_list[batch_size * i : batch_size * (i + 1)]\n",
    "    )\n",
    "    attention_mask_batch = torch.LongTensor(\n",
    "        attention_mask_list[batch_size * i : batch_size * (i + 1)]\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(\n",
    "            ids_batch, attention_mask=attention_mask_batch\n",
    "        )\n",
    "    embeddings.append(batch_embeddings[0][:, 0, :].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89812f5",
   "metadata": {},
   "source": [
    "Llama a la función concatenate() para concatenar todos los insertados en una matriz de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c2b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08c81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "as características están listas. ¡Es hora de entrenar el modelo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
