{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "323ed4cd",
   "metadata": {},
   "source": [
    "Clasificación con insertados\n",
    "\n",
    "Ejercicio\n",
    "\n",
    "Entrena un modelo de regresión logística mediante insertados. Imprime el valor de exactitud para el conjunto de entrenamiento.\n",
    "\n",
    "Calcular los insertados de BERT lleva mucho tiempo (si no estás usando una GPU), por lo que te sugerimos tomar solo 200 elementos aleatorios del conjunto. Los elementos se guardan en el archivo imdb_reviews_200.tsv. Divídelos en conjuntos de entrenamiento y prueba en una proporción de 50:50 para una prueba correcta.\n",
    "\n",
    "El objetivo se almacena en la variable pos.\n",
    "\n",
    "Así es como puedes dividir las reseñas en conjuntos de entrenamiento y prueba:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "\n",
    "¡Es correcto!\n",
    "\n",
    "Los insertados son características poderosas que te permiten construir un modelo bastante útil, incluso con pequeños conjuntos de datos, ya que representan un contexto específico en su espacio vectorial. Sin embargo, necesitarás otros modelos que puedan calcular insertados a partir del conjunto de datos original. ¡Afortunadamente, BERT y otros modelos sofisticados pueden resolverlo por ti!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4c918a",
   "metadata": {},
   "source": [
    "Inicialización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abca1d8a",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00205f99",
   "metadata": {},
   "source": [
    "Variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da56d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables globales\n",
    "# Limits process to 200 samples\n",
    "max_sample_size = 200\n",
    "\n",
    "# Load data\n",
    "df_reviews = pd.read_csv('/datasets/imdb_reviews_200.tsv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64ede49",
   "metadata": {},
   "source": [
    "Preprocesamiento para BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d89cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts text into tokens that BERT can undestand\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "ids_list = []\n",
    "attention_mask_list = []\n",
    "max_length = 512\n",
    "\n",
    "for input_text in df_reviews.iloc[:max_sample_size]['review']:\n",
    "    ids = tokenizer.encode(input_text.lower(), add_special_tokens=True, truncation=True, max_length=max_length)\n",
    "    padded = np.array(ids + [0]*(max_length - len(ids))) # Pad the shorter sequences with zeros so that they all have length 512\n",
    "    attention_mask = np.where(padded != 0, 1, 0) # Create a mask. assing 1 for real tokens and 0 for paddings\n",
    "    ids_list.append(padded)\n",
    "    attention_mask_list.append(attention_mask)\n",
    "\n",
    "# Obtains insterted\n",
    "config = transformers.BertConfig.from_pretrained('bert-base-uncased')\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# por lo general, el tamaño del lote es igual a 100, \n",
    "# pero lo podemos configurar en valores más bajos para reducir los requisitos de memoria\n",
    "batch_size = 25    \n",
    "\n",
    "# Generates embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Batch processing: Process data in batches of 25 to save memory\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Uso del dispositivo {device}.')\n",
    "model.to(device)\n",
    "\n",
    "# Extract token embedding [CLS]: [:,0,:] takes the first token from each sequence, \n",
    "# which in BERT contains aggregated information of the entire sentence\n",
    "for i in tqdm(range(len(ids_list) // batch_size)):\n",
    "    \n",
    "    ids_batch = torch.LongTensor(ids_list[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask_list[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        batch_embeddings = model(ids_batch, attention_mask=attention_mask_batch)\n",
    "    # Move tensors between CPU/GPU: Optimize performance\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].detach().cpu().numpy())\n",
    "\n",
    "    # Output\n",
    "#     Uso del dispositivo cpu.\n",
    "# 100%\n",
    "#  8/8 [12:31<00:00, 94.16s/it]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3343db25",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4bc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings) # Embeddings de BERT (768 dimensiones por muestra)\n",
    "target = df_reviews.iloc[:max_sample_size]['pos'] # Etiquetas (1=positivo, 0=negativo)\n",
    "\n",
    "print(features.shape)\n",
    "print(target.shape)\n",
    "\n",
    "# Output\n",
    "#(200, 768)\n",
    "#(200,)\n",
    "\n",
    "# Divides model 50:50 for train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.5, random_state=42)\n",
    "log_reg = LogisticRegression(max_iter=100)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Accuracy fot train and test\n",
    "train_acc = log_reg.score(X_train, y_train)\n",
    "test_acc = log_reg.score(X_test, y_test)\n",
    "\n",
    "print(train_acc)\n",
    "print(test_acc)\n",
    "\n",
    "# Output\n",
    "# 1.0\n",
    "# 0.85\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
